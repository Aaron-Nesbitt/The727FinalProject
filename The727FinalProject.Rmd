---
title: "The727FinalProject"
author: "Aaron Nesbitt and Jessica Valencia"
date: '2022-12-01'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(readr)
library(dplyr)
library(rtweet)
library(ggplot2)
library(plyr)
library(tidyverse)
library(tidytext)
library(ggmap)
```

We search we original tweets, allowing for up to 18 thousand. We ran the function at 5 pm on Tuesday November 29th.

```{r}
#musktweetsfinal <- read_csv("C:\\Users\\valen\\Downloads\\musktweetsfinal.csv")
#muskTweets <- read_csv("C:\\Users\\aanes\\Downloads\\muskTweets.csv")
```

```{r eval=FALSE, include=FALSE}
#musk <- search_tweets(
#  q = "musk Twitter, lang:en",
#  n = 18000,
#  include_rts = FALSE
)
```

```{r}
head(musktweetsfinal$text, n=10)
```

```{r}
colnames(musktweetsfinal)
```

```{r}
library(quanteda)

opinionWords = c('Apple', 'apple','@apple', '@Apple', '#Apple', '#apple', 'Apple\'s', 'apple\'s','-Apple','Apples','@AppleSupport','@AppleTVPlus','#MuskTwitterAppleMeltdown','@Apple!','#AppleMusicLive')

muskTweets = data.frame()
doNotNeed = data.frame()

for(i in 1:nrow(musktweetsfinal)){
  # break up tweet into individual words
  tweet = musktweetsfinal$text[i]
  tweet = tolower(tweet)
  words = tokens(tweet)
  # if it contains an irrelevant word, put it in the irrelevant data frame
  if(length(intersect(words[['text1']], opinionWords))>0){
    doNotNeed = rbind(doNotNeed, musktweetsfinal[i,])
  }
  else{
    muskTweets = rbind(muskTweets, musktweetsfinal[i,])
  }
}
```




This is a sentiment analysis of the tweets. 
```{r, eval=FALSE}
install.packages("SentimentAnalysis")
library(SentimentAnalysis)
sentiments = analyzeSentiment(iconv(as.character(muskTweets$text), to='UTF-8'))
head(sentiments)
```

```{r}
#PULL IN DATA FROM PREVIOUS CHUNK USING CSV FILE 
#library(readr)
#sentiments <- read_csv("C:/Users/aanes/Downloads/sentiments.csv")
#View(sentiments)
```

```{r}
#library(vader)
# = vader_df(muskTweets$text)
#sentiments$Vader = vader_scores$compound
#ggplot(sentiments, aes(x=WordCount, y=Vader)) + geom_point(alpha=.1) + geom_smooth()
```




```{r}
ggplot(sentiments, aes(x=WordCount, y=SentimentQDAP)) + geom_point(alpha=.1) + geom_smooth()
```

```{r}
library(vader)
test <- muskTweets[1:1000,]
vader_scores = vader_df(test$text)
```
```{r}
test2 <- muskTweets[1001:3000,]
vader_scores2 = vader_df(test2$text)
```



```{r}
test3 <- muskTweets[3001:5000,]
vader_scores3 = vader_df(test3$text)
```
```{r}
test4 <- muskTweets[5001:7000,]
vader_scores4 = vader_df(test4$text)
```

```{r}
test5 <- muskTweets[7001:9000,]
vader_scores5 = vader_df(test5$text)
test6 <- muskTweets[9001:11000,]
vader_scores6 = vader_df(test6$text)
```

```{r}
test7 <- muskTweets[11001:13000,]
vader_scores7 = vader_df(test7$text)
test8 <- muskTweets[13001:14193,]
vader_scores8 = vader_df(test8$text)
```


```{r}
allvader <- rbind(vader_scores, vader_scores2, vader_scores3,vader_scores4,vader_scores5,vader_scores6,vader_scores7,vader_scores8 )
```



```{r}
sentiments$Vader = allvader$compound
ggplot(sentiments, aes(x=WordCount, y=Vader)) + geom_point(alpha=.1) + geom_smooth()
```


```{r}
write.csv(sentiments, "C:\\Users\\aanes\\Downloads\\sentiments.csv")
```



